{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kaonavi.csv', index_col='employee_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memo\n",
    "- input: image ( height: 120, width: 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "\n",
    "def build_generator():\n",
    "    input_shape = (100,)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(20 * 15 * 128, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(Reshape((20, 15, 128)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(UpSampling2D(size=3))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(UpSampling2D())\n",
    "    \n",
    "    model.add(Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    # print(model.summary())\n",
    "    # \n",
    "    # noise = Input(shape=input_shape)\n",
    "    # img = model(noise)\n",
    "    # return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = build_generator()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Flatten, Dropout\n",
    "\n",
    "def build_discriminator():\n",
    "    input_shape = (120, 90, 1)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, input_shape=input_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_discriminator()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル作り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_ids = df[df.job_type=='エンジニア'].index\n",
    "print('length of employee_ids: {}'.format(len(employee_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 30\n",
    "NUM_EPOCH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "# モデルのコンパイル\n",
    "optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "d_opt = Adam(lr=1e-5, beta_1=0.1)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=d_opt)\n",
    "\n",
    "discriminator.trainable = False\n",
    "generator = build_generator()\n",
    "dcgan = Sequential([generator, discriminator])\n",
    "g_opt = Adam(lr=2e-4, beta_1=0.5)\n",
    "dcgan.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
    "\n",
    "# 画像の読み込み\n",
    "images = [np.array(Image.open('faces_monochrome/{}.png'.format(i))).reshape(120, 90, -1) for i in employee_ids]\n",
    "\n",
    "# 初期化とか\n",
    "num_batches = int(len(images) / BATCH_SIZE)\n",
    "test_noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for index in range(num_batches):\n",
    "        noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "        image_batch = images[index * BATCH_SIZE:(index+1) * BATCH_SIZE]\n",
    "        generated_images = generator.predict(noise)\n",
    "\n",
    "        # update discriminator\n",
    "        X = np.concatenate((np.array(image_batch), generated_images))\n",
    "        y = [1]*BATCH_SIZE + [0]*BATCH_SIZE\n",
    "        d_loss = discriminator.train_on_batch(X, y)\n",
    "        d_losses.append(d_loss)\n",
    "\n",
    "        # update generator\n",
    "        noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "        g_loss = dcgan.train_on_batch(noise, np.ones((BATCH_SIZE, 1)))\n",
    "        g_losses.append(g_loss)\n",
    "\n",
    "    print(\"epoch: %d, g_loss: %f, d_loss: %f\" % (epoch, g_loss, d_loss))\n",
    "    res = Image.fromarray(np.array(generator.predict(test_noise)[0][:,:,0]*300, dtype='uint8'))\n",
    "    res.save('generated_images/epoch_{}.png'.format(epoch))\n",
    "\n",
    "# visualization\n",
    "fig, (ax_d, ax_g) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "ax_d.plot(d_losses, linewidth=2)\n",
    "ax_d.set_title('loss of discriminator')\n",
    "\n",
    "ax_g.plot(g_losses, linewidth=2)\n",
    "ax_g.set_title('loss of generator')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
